# CircleCI 的事故+中断:我们的剧本和我们学到的东西

> 原文：<https://circleci.com/blog/incidents-outages-at-circleci-our-playbook-and-what-we-ve-learned/>

**来自出版商的说明:**您已经找到了我们的一些旧内容，这些内容可能已经过时和/或不正确。尝试在[我们的文档](https://circleci.com/docs/)或[博客](https://circleci.com/blog/)中搜索最新信息。

* * *

二月份，当 AWS [经历了 S3 的中断](https://techcrunch.com/2017/03/02/aws-cloudsplains-what-happend-to-s3-storage-on-monday/)时，CircleCI(和基本上一半的互联网)受到了严重影响。虽然停机从来都不好玩，但它是检查您的事故计划、团队合作以及改进您的系统和性能的最佳机会。

虽然我们尽了最大努力来提供不间断的服务，但我们(很少)会遇到服务质量下降，甚至中断的情况。有时，这是因为我们团队引入的问题，或者我们犯的错误。

此外，我们还依赖于许多其他服务(GitHub、Bitbucket、AWS、Heroku 等)。).因此，当其中一个或多个经历停机时，我们也会感到痛苦。

以下是我们所做的——在某些情况下，当事情变得不顺利时，我们是如何艰难地学会做这件事的。

* * *

有很多不同的方法来处理事件(只是谷歌“事件响应”)，但有几件事是所有人都有的，那就是首先要有一个计划，无论多么简单，其次要遵循计划。这两者现在看起来都很明显，但令人惊讶的是，有多少人认为他们可以让聪明的工程师解决问题，并以此作为他们的“回应”。

## 我们事故响应计划的参数

在 CircleCI，我们的事故由许多团队的人员管理，我们都使用许多规则:

1.  任何人都可以宣布事故。通常不是 SRE 团队或工程师注意到事情“不太对劲”

2.  一旦宣布发生事故，对话将转移到我们的#incident 聊天室，这有助于整合有关事故的所有信息。

3.  然后，我们决定由谁来扮演两个核心角色:指挥官和通信人员(我将在后面的文章中详细介绍)
    *   事故指挥官-负责事故的人员
    *   通信-负责状态更新的人员
4.  确定谁在工程部门提供帮助

## 事故期间响应指南

在我们满足了上面的标准之后，我们开始调试并确定中断的根本原因。我们通常也开始确定需要什么样的临时变更来处理停机似乎总是会产生的级联“混乱”。

在事件响应的最开始，您需要明确谁在扮演上述角色。事故指挥官需要是不一定致力于解决事故但也必须完全在场的人-他们是确保评论和小待办事项不会被忘记的人。他们的另一个主要任务是确保沟通渠道没有无关的闲聊。

事故指挥官还需要非常依赖通信人员，这样他们就不会陷入在事故中经常出现的“嘿，状态如何”的问题中——通信人员也是确保状态页和其他面向客户的通信等项目得到干净处理的人。

我们采用了一种状态策略，通信人员通过使用 20 分钟计时器提醒团队需要更新，然后指挥官将推荐更新，通信人员将按照惊人的风格和语气指南(包括状态消息的示例)进行修改。这些例子是由我们的营销团队编写的，让我们在深陷问题的时候，可以避开文字推敲。

一旦确定了事件的根本原因，指挥官将指示通信人员，我们需要将事件状态更改为“已识别”。当我们部署一个补丁时，以及当我们确信这个补丁解决了问题时，也会发生类似的变化。修复得到验证后，我们会维持 30 分钟的最终“监控”阶段，以确保事件得到真正解决。

我们的事件响应计划的一个关键部分是，我们还要确保响应事件的每个人都有机会休息、获得食物和其他自我护理——如果团队没有足够的睡眠、食物或思考时间，任何事情都无法解决。

我们关注自我护理的另一个方面是了解一个事件是由整个团队负责的，这使我们能够利用位于多个时区的员工。长时间运行的事件通常会跨越时区，因为它们流向该时区的工作日。让事故“全天候”运行的能力确实是可能的，因为我们努力确保我们系统的知识在我们所有的团队中传播。

## 惨痛的教训

我们的事件响应计划中的一些其他项目我们不得不艰难地学习:)

*   我们不会在事故期间更改服务器数量，尤其是在与 AWS 相关的事故期间。AWS 经常限制 API 调用，然后你最终会与成千上万也在尝试启动实例的其他公司竞争。
*   在可能的情况下，我们通过关闭低优先级的后台进程来释放额外的资源，从而减轻负载。
*   我们将#incident Slack 渠道中的闲聊和猜测保持在最低限度，将附带讨论重定向到我们正常的#ops 和#engineering 渠道。不参与事故处理的工程师监控#incident 以了解所涉及的问题并不罕见。把#incident 无情地保持在话题上需要一些练习和自律，但是可以做到。
*   如果合适的话，我们还会禁用某些功能，以减少客户流失。这方面的一个例子是我们对所有“循环调试”作业的自动重试，如果在外部中断期间让它继续运行，重试次数很容易淹没我们的作业队列。

## 事件后行动项目

事件结束后，真正的工作才开始。即使只有事故指挥官审查日志并更新文档和/或操作手册，您也应该始终进行事故事后分析。如果事件是外部的，您仍然可以在基础架构中发现可以改进的边缘情况或单点故障。如果他们因为各种各样的现实原因而无法改善，那么至少在他们周围增加监控，这样你就可以在行为变成事故之前*得到警告。*

事后分析之后，创建事故报告并在内部发布。在公共场所张贴我们的事件报告是我们在收到客户反馈后才开始做的事情，他们非常有兴趣了解事件的“原因”和“方式”,因此我们将此添加到了事件清单中。

## 结案建议

关于事故响应计划，我有两个最后的建议。第一个建议是，你应该在每次事故后回顾你的计划，看看如何改进。多年来，我们的计划发生了重大变化，更新计划是获取和保存有关事件响应的知识和最佳实践的最佳方式。

第二个建议是确保每个人都知道你的事件响应计划，并知道如何使用它。像许多事情一样，如果你的团队不知道这个计划，不知道在哪里找到它，或者不知道如何实现它，那么这个计划是没有用的。