# 确定性构建-持续集成| CircleCI

> 原文：<https://circleci.com/blog/preserve-build-integrity-prevent-problems-deterministic-builds/>

## 为什么确定性构建很重要？

**再现性和可靠性。**

客户在支持单上最常说的话是，他们的构建突然失败了，尽管他们最终“什么都没有改变”。[这几乎从来不是真的](https://circleci.com/blog/troubleshooting-unexplained-build-failures-the-mysterious-case-of-nothing-changed/)。

在这篇文章中，我想谈谈确定性构建。这里的想法是在一个构建中尽可能减少变化的部分。这意味着更少的神秘的失败构建，更少的支持票(对你和我们来说)，并且可能通过简单地重新运行构建来完全相同地复制意外删除的二进制文件。我们都知道测试很重要。然而，一个构建中的变量越多，您对测试的信心就越低。随着目标的移动，在一个场景中通过的测试可能在 3 次提交后就不再通过了，即使有“相同的”依赖关系。

通过确保您的构建是真正确定的，您将减少您的构建中变化的部分，以便增加您的测试套件中的信心和增加可再现性。

在[持续集成(CI)](https://circleci.com/continuous-integration/) 的背景下，开发人员或组织可能会有许多方法来优化他们的构建。有一些众所周知的优化:[减少构建时间](https://circleci.com/blog/why-is-my-build-slow/)或者[减少反复测试](https://circleci.com/blog/using-insights-to-discover-flaky-slow-and-failed-tests/)。然而，这些策略忽略了大局。诸如此类的优化都集中在一个单一的构建上，只考虑了一部分的情况。考虑过去和未来的构建以及它们之间的关系也很重要。

> 把你的构建想象成一个连续体:随着时间的推移，一系列相互关联的部分。

通过现在采取主动措施，您可以防止将来出现问题，并保持以前构建的完整性。

## 什么是确定性构建？

确定性构建可以在提交时、明天甚至下个月“实时”运行，并以完全相同的结果结束。您可以想象从一个构建第一次运行时获取它的“指纹”,并在重新运行时再次这样做。它们应该完全匹配。

我们所说的相同的结果或指纹是什么意思？构建应该能够在将来重新运行，第一次失败的测试再次失败。第一次通过的测试应该会再次通过。构建会产生工件吗？理论上，这些文物应该是完全一样的。对于日志文件或截屏工件来说，这通常很容易，但金鹅是二进制文件。能够运行一个生成软件 X.Y 版本二进制文件的构建，并在 3 个月后生成完全相同的二进制文件，这是使用确定性构建所能达到的高度。

## 我如何使我的构建更具可复制性？

### 版本锁定

这可能是你能做的最简单的改变。尽可能声明依赖关系的最具体版本。例如，对于`npm`，最好运行`npm install react@16.0.0`而不是`npm install react@16.0`或`npm install react@">=16"`。

同样的道理也适用于 [Docker 图像](https://circleci.com/docs/custom-images/)。最好这样做:

```
version: 2
jobs:
  build:
    docker:
      - image: golang:1.9.3
    steps:
... 
```

比它应该做的:

```
version: 2
jobs:
  build:
    docker:
      - image: golang:1.9
    steps:
... 
```

在这两种情况下，去掉版本的 bugfix/patch 号(第三个整数)允许您正在使用的依赖项的版本从您的下面更改出来。今天，`- image: golang:1.9`可能运行版本 1.9.3 的 [Docker 镜像](https://circleci.com/docs/custom-images/)，但是下周的构建可能运行版本 1.9.5 的 Docker 镜像。

当然，总有一个陷阱。包含 bugfix 发布号意味着如果有 bugfix(或安全补丁)，你的软件不会自动开始使用它。你必须决定什么样的维护水平让你感到舒服。`1.9.3`是确定性最强、最不“前沿”的，而`1`是确定性最弱、最“前沿”的。

### 贮藏

是的，缓存。大多数人会考虑缓存一项技术来减少构建时间，这是事实，但它也可以用来增加构建的可靠性。

怎么会？有时，缓存用于存储编译后的二进制文件或以 CPU 密集型方式生成的数据。在这种情况下，我们节省时间，但不一定获得可靠性。当构建通过网络检索多个文件时，缓存可以提高可靠性。怎么会？如果网络暂时中断了，该怎么办？DNS 失败？一旦我们缓存了这些资产，我们就不需要担心这些问题会导致构建失败。如果当我们缓存了所有的依赖项时`npm`的存储库关闭了，理论上我们是好的。构建将继续进行，不会出现问题。

缓存也有助于再现性。如果从互联网上的某个地方下载的资产从现在起两个月后不再可用，因为其所有者没有支付他们的托管费用，该怎么办？如果一个依赖项被释放，并且意外地重用了一个版本标签(Canonical 最近在 Ubuntu 17.10 中就是这么做的)，该怎么办？或者更糟，如果这是恶意发生的？缓存确保了相同的版本，更确切地说，是构建开始时运行的相同代码，是它将再次运行的代码。

## 摘要

一个构建可能永远不会是 100%完全确定的。出于安全原因(安全/补丁发布)或者某种公司政策，一个构建可能必须包含一些“移动部分”。这篇文章背后的真正意义是确保你的构建对于你的用例来说是尽可能确定的。这将确保您的构建在可靠性和可再现性方面得到优化。