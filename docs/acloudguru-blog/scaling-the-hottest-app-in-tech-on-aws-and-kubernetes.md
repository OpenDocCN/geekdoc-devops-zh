# 在 AWS 和 Kubernetes 上扩展最热门的技术应用

> 原文：<https://acloudguru.com/blog/engineering/scaling-the-hottest-app-in-tech-on-aws-and-kubernetes>

与 Blake Stoddard，老 SRE 在 Basecamp / HEY 的云对话。为了清晰起见，这篇采访经过了编辑和压缩。

##### 云发光时发出嘿的声音

Forrest Brazeal:在过去的几周里，Basecamp 的新电子邮件应用 HEY 席卷了整个科技界。也有很多关于“HEYstack”的讨论——你的云基础设施运行在 [AWS](https://acloud.guru/courses/amazon-web-services) 和 Kubernetes 上。既然 Basecamp 以选择“无聊的技术”而闻名，是什么让你考虑在云中运行你最新的应用？

*![DmBabl0G_400x400](img/c0ff1dc0359dc2ac0e394ddd3316cc31.png)* 布雷克·斯托达德:Basecamp 过去一直在内部数据中心托管我们的 SaaS 软件，但几年前我们决定尝试在云上运行我们的一些工作负载。

我们知道我们希望使用容器来更好地协调我们的基础架构部署，因此我们在 2016 年开始使用 AWS ECS。2018 年，当我们重新评估我们如何管理容器编排时，Kubernetes 是我们的选择。

我们给了谷歌 Kubernetes Engine ( [GKE](https://acloudguru.com/course/google-kubernetes-engine-gke-beginner-to-pro) )一次机会——因为他们很自然地想到了管理的 Kubernetes——但我们在那里遇到了一些问题，最终决定在 2019 年初离开 GCP。

因为我们已经从最初的 ECS 迁移中获得了 AWS 中的一些其他资源，所以给 EKS 一个机会似乎是很自然的。自该产品于 2017 年首次发布以来，AWS 团队在解决我们与 EKS 之间的各种问题方面取得了很大进展。

快进到今天，他们主要依靠 AWS 托管服务——EKS 有许多 spot 实例，但也有 Aurora MySQL、Elasticache Redis 和 AWS 的托管 Elasticsearch。

**等等，你真的把 Kubernetes 的工作负载从 GCP 迁移到了 AWS？这是“多云”架构带来回报的罕见用例吗？**

[笑]我想是的。我们非常重视可移植性，所以我们想知道，如果有必要，我们可以在云(和本地)之间[迁移工作负载](https://acloudguru.com/blog/business/what-is-cloud-migration)。

不过，我们对此很务实。Basecamp 第一次尝试 AWS 上的容器是通过 ECS，我们仍然为多个生产工作负载运行 ECS。但是我们发现我们的部署、监控和日志记录首选项在 EKS 上比在 ECS 上工作得更好。

我们还发现 Kubernetes 不像 ECS 那样是一个黑箱。在我们使用 ECS 的几年中，我们仍然偶尔会遇到任务无法启动等问题。然后你花几分钟时间在用户界面上摸索，试图弄清楚发生了什么，为什么 X 不启动，为什么 Y 被挂起。即便如此，你实际上能做些什么来干预的选择也很少。

有了 Kubernetes，我们可以更深入地了解事情是如何安排的，当事情出错时会发生什么，以及通过强大的 CLI(在我前面提到的部署首选项之上)检查正在发生什么的增强能力。

然而，你使用的是托管 EKS，而不是在 EC2 实例上托管 Kubernetes。如何在可移植性和减轻管理负担之间划清界限？

不能保证我们会永远待在 EKS。但是 EKS 作为服务管理一些低级的东西，比如 K8s masters，我们根本不想处理。我的意思是，EKS 控制飞机的费用是每小时 10 美分，也就是说，每个集群每年 820 美元。与工程师的时间相比，这相当便宜，即使考虑到我们运行的集群数量。

如果我们能支付费用进行管理，这样我们就能把时间集中在对公司有更高价值的工程工作上，我们会整天都做这笔交易。

Basecamp 的创始人兼首席技术官 David Heinemeier Hansson 表示他“从未像过去两周这样开心地待在云上”公共云如何帮助您处理意外流行的新服务的流量？

如果没有公共云，我们就无法满足对 HEY 的需求。我的意思是，我们计划在几个月内拥有 50，000 名活跃用户，但我们在两周内就超过了这个数字。

在传统的数据中心世界中，没有好的方法来跟上这种急剧增长的步伐。您要么预先为大规模过度配置付费，要么一直忙于安装和堆叠新硬件。

相反，AWS 让我们可以在需要时增加新的计算能力。这对于测试来说也很棒——在公开发布 HEY 之前，我们根据几个月来对该产品的内部使用模型对该应用进行了负载测试。云是这方面的完美选择——它让应用程序尝试不同的计算和数据库规模变得超级简单。

最后，根据需求，扩展比我预期的要顺利得多。我们已经做了足够的测试，知道基础设施是可靠的。这只是水平扩展我们的集群来处理前端和后端负载的问题。

**随着您的发展，[云成本](https://acloudguru.com/blog/business/continuous-cloud-cost-optimization)正在成为您的痛点吗？**

实际上，我的办公室里挂着一顶写着“云计算沙皇”的帽子，因为我花了很多时间处理这个问题。从原始基础设施成本的角度来看，我们可以更便宜地在内部运行我们的工作负载。我们走向云是为了创造更多的价值，而不是为了少花钱。

但是我在关注一些事情。我们运行大约 90%的现场实例混合，这降低了我们的计算成本。数据传输总是一个大项目。如果你相信的话，我们从 S3 向互联网传输数据的费用比我们所有的 EC2 计算都要高。

另一个问题是:有些服务会在你最意想不到的时候产生账单，比如 CloudWatch 日志。它很容易与 EKS 融合！只需一键点击！然后你看着你的账单，想着“每天多出来的 50-60 美元是从哪里来的？”

根据你现在对 HEY 如何扩展的了解，如果你可以从头开始重新设计这款应用，你会做出任何不同的架构选择吗？

当我为 HEY 设计基础设施时，我首先想到了两个错误。我们使用 Terraform，我编写了一个新模块来管理我们的 VPC，以取代我们在 2016 年编写的模块。

第一个错误:我没有处理 IPv6 子网，现在它回来咬我(随着本地 IPv6 支持即将来到 EKS，到那时解决这个问题就好了)。

第二个错误是我计划了静态数量的可用区域。原来不是每个 AWS 地区都有 4 个 az——us-east-1 和 us-west-2 有，但 us-east-2 没有！

那么，他们现在正在多个地区运营？

是的，它目前在美国东部-1 和美国西部-2。我们希望很快转向真正的主动-主动部署，在区域之间进行基于延迟的路由。实际上，我们已经在生产环境中运行了几次，但是对于需要写入的请求，要获得 80 毫秒的主区域延迟，同时确保没有过时的读取，这是很棘手的。

同样，我们已经花了很多时间考虑分片和数据局部性。我很想让数据更接近最终用户，但这真的是白日做梦。我们在俄罗斯有客户，尽管我们这边很快就能呈现他们的请求，但往返旅行让一切都感觉慢了一些。

我更喜欢 GCP 的全局负载平衡器，你可以跨多个活动区域进行任播。既然我们在 AWS，我们就把[全球加速器](https://aws.amazon.com/global-accelerator/?blogs-global-accelerator.sort-by=item.additionalFields.createdDate&blogs-global-accelerator.sort-order=desc&aws-global-accelerator-wn.sort-by=item.additionalFields.postDateTime&aws-global-accelerator-wn.sort-order=desc)视为通往那里的道路。我们希望这将有助于加快我们的出站流量，因为数据在到达公共互联网之前会在 AWS 网络上停留很长时间，但使用它会有很高的额外成本，不能保证它确实填补了我们正在寻找的空白。

对于那些想在 AWS 上实现“HEYstack”的人，最后有什么至理名言要分享吗？

请密切关注您的数据库模式！我们非常依赖关系数据库，构建模式会产生可怕的级联效应。

第二，尽可能多的缓存。嘿渲染了很多电子邮件，我们已经让它变得很快，但在规模上它是计算密集型的。

我想你刚刚列出了计算机科学中最难的两个问题，命名事物和缓存失效。一个接一个的失误是另一个最困难的问题…还有一件事吗？

你不应该仅仅因为某项技术是流行的，就选择它并将其集成到你的堆栈中。10 年前，我们并没有因为云很酷就跳入云中，感觉我们采用 Kubernetes 相对较晚，我们没有使用服务网格。我们已经让这些技术成熟，现在我们正在获得真正的价值。

我们的故事(和很多其他的一样！)表明，您不必越过最前沿就能获得云的好处。