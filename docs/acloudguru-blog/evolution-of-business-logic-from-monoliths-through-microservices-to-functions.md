# 业务逻辑的演变，从单片到微服务，再到功能

> 原文：<https://acloudguru.com/blog/engineering/evolution-of-business-logic-from-monoliths-through-microservices-to-functions>

运行应用软件的全部目的是交付某种商业价值。业务价值是通过创建业务逻辑并对其进行操作来交付的，因此它可以向一些用户提供服务。

创建业务逻辑和使用该逻辑向用户提供服务之间的时间是*实现价值的时间*。提供这种价值的成本是创造成本加上交付成本。

### 从微服务到事件驱动功能的业务逻辑

过去，成本很高，效率问题占主导地位，高价值实现时间被视为常态。今天，当组织测量和优化他们的活动时，在竞争压力、技术进步和成本降低的推动下，价值实现时间正在成为一个主导指标。

换句话说，要增加投资回报，你需要找到增加回报的方法，更早地开始回报价值，或者减少投资。当成本占主导地位时，这就是重点所在，但随着成本降低和软件影响增加，重点转向更早获得回报。

### 单片应用

随着技术在过去十年的进步，[我们已经看到了从单片](https://acloudguru.com/blog/engineering/if-you-cant-strangle-the-monolith-starve-it-to-death)应用到微服务的演变，并且现在看到了由 [AWS Lambda](https://acloudguru.com/blog/engineering/aws-lambda-is-winning-but-first-it-had-to-die) 引领的无服务器事件驱动功能的兴起。什么因素推动了这种演变？低延迟消息传递实现了从单片到微服务的转变，低延迟供应实现了向[λ](https://aws.amazon.com/lambda/)的转变。

首先，十年前，在当时的限制下，单一应用程序是交付业务逻辑的最佳方式。这些限制发生了变化，大约五年前，最佳选择转向了微服务。新的应用程序开始建立在微服务架构上，在过去的几年中，工具和开发实践发生了变化，以支持微服务的发展。

今天，事件驱动的功能正在发生另一种转变——因为潜在的约束已经改变，成本已经降低，价值实现时间的根本改进是可能的。

在接下来的内容中，我们将详细探讨变化的不同维度:交付技术、硬件能力和组织实践，并了解它们是如何结合起来推动这一演变的。

### 过程优化的早期

在这段旅程的开始，运输成本占主导地位。采购、配置和部署硬件需要很长时间，而软件安装本身就是手工制作的项目。

为了优化交付，最佳实践是在每个版本中将这种高成本分摊到大量的业务逻辑中，并且相对不频繁地发布，对于许多组织来说，价值实现时间以月来衡量。考虑到基础架构变更的交付周期较长，有必要提前预配置额外的容量，这导致平均利用率非常低。

降低交付成本的第一步集中在流程自动化上。许多组织开发定制脚本来部署新硬件，以及安装和更新应用程序。

### DevOps 运动

最终，像木偶和[主厨](https://aws.amazon.com/opsworks/chefautomate/)这样的通用框架变得流行起来，“基础设施即代码”加速了更新的交付。当运营团队采用敏捷软件开发实践并与开发人员密切合作以将价值实现时间从几个月缩短到几天时，DevOps 运动就开始了。

脚本可以改变已经存在的内容，但快速增长的企业或工作负载不可预测的企业很难快速调配新容量。引入自助式 API 调用来使用 [Amazon EC2](https://aws.amazon.com/ec2/) 自动供应云容量解决了这个问题。

当开发人员能够使用 web 服务直接自动化许多操作任务时，第二波开发运维浪潮出现了。运营团队基于云服务构建并运行高度自动化的 API 驱动平台，为开发团队提供自助部署和自动扩展能力。

及时部署容量并按小时支付实际所需费用的能力大大提高了平均利用率，并自动处理意外的工作负载高峰。

### 容器的时代

当 docker 让每个人都能轻松使用容器时，又一波优化浪潮到来了。Docker 容器提供了一种方便的捆绑包格式，它包括一组固定的依赖项，一个比进程提供更多隔离但比虚拟机实例少的运行时，以秒为单位的启动时间，以及大量的内存节省。

通过将许多容器打包到一个实例中，并将运行时间四舍五入到分钟或秒而不是小时，甚至可以实现更高的利用率。基于容器的连续交付工具也加快了开发人员的工作，缩短了价值实现的时间。

当有合理可预测的工作量进来时，容器可以以高利用率水平运行，但是许多工作负载会在很长一段时间内达到峰值或降至零。例如，工作场所中使用的应用程序可能仅在一周 168 个小时中的 40 个小时是活动的。

为了保持高可用性，通常将应用程序实例分布在三个可用性区域，甚至每个区域需要多个实例。因此，一个服务的最小足迹是六个实例。如果我们想缩小到零，我们需要一种方法在事件发生时启动应用程序的一部分，并在事件结束时关闭它。

这是 AWS Lambda 功能的一个关键部分，它通过只对正在使用的容量收费，以 0.1 秒为增量，将峰值和低使用率工作负载转化为有效的 100%利用率，并根据需要从零扩展到非常高的容量。不需要考虑或供应服务器，这就是为什么这通常被称为无服务器模式。

交付技术的进步为价值实现时间的改进提供了垫脚石，但在过去十年中，还有其他潜在的变化导致了最佳实践的一系列转变。

### CPU 和网络技术的进步

一组业务逻辑的最佳大小取决于 CPU、网络、内存和磁盘资源的相对成本(美元和访问时间),以及服务的延迟目标。

对于人类终端用户等待一些业务逻辑提供服务的常见情况，总的服务时间需求没有太大变化。在过去十年左右的时间里，人们的认知和期望并没有像基础技术那样发生很大的变化。

在过去十年中，CPU 速度增长相当缓慢，因为时钟速率在几 GHz 时遇到了瓶颈，但是片上缓存要大得多，内核数量反而增加了。内存速度和大小也取得了相对缓慢的进展。

网络速度大大加快，常见部署从 1gb 发展到 10g，现在是 25GBit，软件协议也更加高效。当常见的做法是通过 1gb 网络发送 XML 有效负载时，通信开销会限制业务逻辑，使其位于大型整体服务中，直接连接到数据库。

十年后，编码比 25Gbit 网络至少高效一个数量级——这意味着通信成本降低了两个数量级以上。

换句话说，在十年前传递和处理一条消息所需的时间内，在服务之间发送 100 到 1000 条消息是可能的。这是远离单一应用程序的一个关键促成因素。

### 存储和数据库技术的进步

在过去十年中，存储和数据库也经历了一场革命。整体式应用程序根据复杂的关系数据库(RDBMS)模式将其业务逻辑映射到事务，该模式将所有表链接在一起，并允许协调的原子更新。

十年前，最佳实践是实现少量大型集中式关系数据库，通过存储区域网络连接到使用磁盘的昂贵磁盘阵列，前面是大型缓存。

如今，缓存磁盘已经被固态磁盘所取代。区别在于，随着缓存命中率的变化，读取从缓慢、昂贵且不可预测转变为持续快速且几乎无限制。由于损耗均衡算法和其他影响，写入和更新从高速缓存磁盘的快速变为固态磁盘的不可预测。

新的“NoSQL”数据库架构变得流行有几个原因——但我们在这里关注的区别是，它们具有简单的模式模型，并利用了固态存储的特性。简单模式强制将在同一个关系数据库中链接在一起的数据表分离到多个独立的 NoSQL 数据库中，推动了业务逻辑的分散化。

Amazon DynamoDB 数据存储服务从一开始就被设计为只在固态磁盘上运行，为请求提供了极其一致的低延迟。Apache Cassandra 的存储模型会生成大量随机读取，并在没有更新的情况下进行不频繁的大型写入，这非常适合固态磁盘。

与关系数据库相比，NoSQL 数据库提供了简单但极具成本效益、高可用性和可伸缩性的数据库，并且延迟非常低。NoSQL 数据库越来越受欢迎是远离单一模式和单一应用程序的另一个关键因素。剩余的关系核心模式被清理，更容易扩展，并且正在迁移到诸如 Amazon 的 RDS 和 Aurora 之类的服务。

### 从项目转移到产品

当我们审视 It 领域的变化时，经常会谈到“人员、流程和技术”。我们刚刚看到技术如何通过 AWS Lambda 将部署的利用率和速度发挥到了极致，在不到一秒的时间内就实现了 100%的部署利用率。

它还可以有效地将整体代码基础分解为数百个微服务和功能，并将整体 RDBMS 非规范化为许多简单的可扩展和高度可用的 NoSQL 和关系数据存储。

在过去十年中,“人员和流程”也发生了巨大的变化。让我们考虑一个假设的由 100 个开发者一起建造的整体。为了协调、管理测试并每隔几个月向这个庞然大物交付更新，运行过程的人比编写代码的人多是很常见的。

两倍多的项目经理、测试人员、数据库管理员、操作员等。组织在筒仓中，由票证驱动，管理层级要求每个人都写每周报告，参加大量的状态会议，以及找到时间编写实际的业务逻辑代码！

DevOps 实践、微服务架构和云部署的结合与连续交付流程、基于蜂窝的“两个披萨团队”组织以及票据、会议和管理开销的大幅减少齐头并进。开发人员和产品经理组成的小组在需要时独立编码、测试和部署他们自己的微服务。

开发人员与管理费用的比例正好相反——100 名开发人员对 50 名管理人员。每个开发人员花在会议和等待入场券上的时间更少了，完成了两倍的工作，时间价值提高了一百倍。

这种变化的一个常见的简写就是从*项目*转移到*产品*。大量的项目经理被少得多的产品经理取代。在我这个有点做作的例子中，150 人的产出是过去 300 人的两倍。投资减半，回报快一百倍。许多组织已经在[进行这种转变](http://www.leanessays.com/2017/01/the-end-of-enterprise-it.html)，并且有[类似改进的真实例子](https://devops-research.com/)。

### 函数的早期

基于 Lambda 的应用程序是由几乎完全是业务逻辑的单个事件驱动函数构建的——需要管理的样板文件和平台代码要少得多。现在还为时尚早，但这似乎正在推动另一场彻底的变革。

开发人员的小团队在短短几天内从零开始构建生产就绪的应用程序。他们使用[简短简单的函数和事件](https://acloudguru.com/blog/engineering/building-more-cost-effective-lambda-functions-with-1-ms-billing)将健壮的 API 驱动的数据存储和服务粘合在一起。完成的应用程序已经具有高可用性和可伸缩性、高利用率、低成本和快速部署。

打个比方，想想与一堆乐高积木相比，用一团粘土做一个模型房子需要多长时间。如果有足够的时间，你可以用粘土制作几乎任何东西，它富有表现力，富有创造性，甚至还有一种用于单片应用程序的反模式，称为“[大泥球](https://en.wikipedia.org/wiki/Big_ball_of_mud)”。

乐高积木组合在一起，形成一个受限制的块状模型房子，也很容易扩展和修改，只需很少的时间。此外，还有其他类似于乐高积木的砖块，但它们还不够流行，任何一种基于标准砖块的系统都要比定制的粘土快得多。

如果开发人员生产率的数量级增长是可能的，那么我的示例 100 开发人员 monolith 可以从头开始重写，并在几周内由十名开发人员组成的团队替换。即使你怀疑这是否可行，这也是一个廉价的实验。事件驱动函数的调用延迟是限制复杂应用程序的关键限制之一，但随着时间的推移，这些延迟正在减少。

我真正想说的是，现有的整体式应用程序是应该[原封不动地迁移到云中，还是应该重写](https://medium.com/aws-enterprise-collection/cloud-native-or-lift-and-shift-99970053b25b#.mad2gu19n)，这在很大程度上取决于重写它们的工作量。典型的数据中心到云的迁移将挑选出高度扩展和高变化率的应用程序，以从单片服务器重写到微服务，并将小型或冻结的应用程序原封不动地进行叉车式迁移。

我认为 AWS Lambda 改变了等式，很可能是构建新的和实验性应用程序的默认方式，并且也使它值得进行更多的重写。

我对您的经历非常感兴趣，所以请让我知道您如何看待时间价值在您的环境中的演变。

* * *

## 获得更好职业所需的技能。

掌握现代技术技能，获得认证，提升您的职业生涯。无论您是新手还是经验丰富的专业人士，您都可以通过实践来学习，并在 ACG 的帮助下推进您的云计算职业生涯。

* * *